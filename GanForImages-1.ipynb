{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13254,"status":"ok","timestamp":1768882324963,"user":{"displayName":"Rajesh Chillapalli","userId":"18375985042517881039"},"user_tz":-330},"id":"hJXAWbbyWlPy","outputId":"3da60187-d3e6-4bc1-c790-7ab1ddaee3d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.19.0\n"]}],"source":["# Module 0: Setup (Colab + Imports)\n","\n","# Do NOT pin an older TF version; just ensure it's installed.\n","!pip install -q tensorflow matplotlib tqdm\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, optimizers, losses\n","\n","from tqdm import tqdm\n","\n","print(\"TensorFlow version:\", tf.__version__)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"IUC3nwIEXHER","executionInfo":{"status":"ok","timestamp":1768882324980,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rajesh Chillapalli","userId":"18375985042517881039"}}},"outputs":[],"source":["# Config (you can later move this to a YAML file and parse it)\n","CONFIG = {\n","    \"image_size\": 28,          # MNIST\n","    \"channels\": 1,             # grayscale\n","    \"latent_dim\": 100,\n","    \"batch_size\": 64,\n","    \"buffer_size\": 60000,\n","    \"epochs\": 100,\n","    \"lr\": 0.0002,\n","    \"beta1\": 0.5,\n","    \"train_split\": 0.95,\n","    \"normalization\": \"tanh\",\n","    \"samples_dir\": \"samples\",\n","    \"checkpoints_dir\": \"checkpoints\"\n","}\n","\n","os.makedirs(CONFIG[\"samples_dir\"], exist_ok=True)\n","os.makedirs(CONFIG[\"checkpoints_dir\"], exist_ok=True)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2927,"status":"ok","timestamp":1768882327910,"user":{"displayName":"Rajesh Chillapalli","userId":"18375985042517881039"},"user_tz":-330},"id":"WdngpEQzXgOz","outputId":"db72fe08-dd5e-4cc4-9c2d-81f9032b972b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"output_type":"execute_result","data":{"text/plain":["(1039, 54)"]},"metadata":{},"execution_count":3}],"source":["# Data loader (MNIST as example domain)\n","def load_mnist_dataset(config=CONFIG):\n","    (x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n","\n","    x = np.concatenate([x_train, x_test], axis=0)  # 70k images\n","    x = x.astype(\"float32\")\n","\n","    # Add channel dimension\n","    x = np.expand_dims(x, axis=-1)  # (N, 28, 28, 1)\n","\n","    # Resize if needed\n","    if config[\"image_size\"] != 28:\n","        x = tf.image.resize(x, (config[\"image_size\"], config[\"image_size\"])).numpy()\n","\n","    # Normalization to [-1, 1] for Tanh output\n","    x = (x / 127.5) - 1.0\n","\n","    # Train / test split (for evaluation only)\n","    n = x.shape[0]\n","    n_train = int(config[\"train_split\"] * n)\n","    x_train = x[:n_train]\n","    x_val = x[n_train:]\n","\n","    # Create tf.data pipeline\n","    train_ds = tf.data.Dataset.from_tensor_slices(x_train)\\\n","        .shuffle(config[\"buffer_size\"])\\\n","        .batch(config[\"batch_size\"], drop_remainder=True)\n","\n","    val_ds = tf.data.Dataset.from_tensor_slices(x_val)\\\n","        .batch(config[\"batch_size\"], drop_remainder=True)\n","\n","    return train_ds, val_ds\n","\n","train_ds, val_ds = load_mnist_dataset(CONFIG)\n","len(list(train_ds)), len(list(val_ds))\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":968},"executionInfo":{"elapsed":2120,"status":"ok","timestamp":1768882330033,"user":{"displayName":"Rajesh Chillapalli","userId":"18375985042517881039"},"user_tz":-330},"id":"-wcuSO6dXkac","outputId":"fd51dca0-3717-4cd2-85b7-1fb1518bac29"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"Generator\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Generator\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │     \u001b[38;5;34m1,254,400\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │        \u001b[38;5;34m50,176\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m524,288\u001b[0m │\n","│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m131,072\u001b[0m │\n","│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │           \u001b[38;5;34m577\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,254,400</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,176</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">577</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,961,281\u001b[0m (7.48 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,961,281</span> (7.48 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,935,809\u001b[0m (7.38 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,935,809</span> (7.38 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m25,472\u001b[0m (99.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,472</span> (99.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"Discriminator\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Discriminator\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,088\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m131,200\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m6,273\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,273</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,073\u001b[0m (543.25 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,073</span> (543.25 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m138,817\u001b[0m (542.25 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">138,817</span> (542.25 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n","</pre>\n"]},"metadata":{}}],"source":["def build_generator(config=CONFIG):\n","    latent_dim = config[\"latent_dim\"]\n","    img_size = config[\"image_size\"]\n","    channels = config[\"channels\"]\n","    img_shape = (img_size, img_size, channels)\n","\n","    model = models.Sequential(name=\"Generator\")\n","\n","    # Fully connected -> reshape to small feature map\n","    model.add(layers.Input(shape=(latent_dim,)))\n","    model.add(layers.Dense(7 * 7 * 256, use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.ReLU())\n","    model.add(layers.Reshape((7, 7, 256)))\n","\n","    # Up-sampling block 1\n","    model.add(layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\", use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.ReLU())\n","\n","    # Up-sampling block 2\n","    model.add(layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.ReLU())\n","\n","    # Output layer\n","    model.add(layers.Conv2D(channels, kernel_size=3, padding=\"same\", activation=\"tanh\"))\n","\n","    return model\n","\n","\n","def build_discriminator(config=CONFIG):\n","    img_size = config[\"image_size\"]\n","    channels = config[\"channels\"]\n","\n","    model = models.Sequential(name=\"Discriminator\")\n","    model.add(layers.Input(shape=(img_size, img_size, channels)))\n","\n","    model.add(layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","\n","    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(1, activation=\"sigmoid\"))\n","\n","    return model\n","\n","\n","generator = build_generator(CONFIG)\n","discriminator = build_discriminator(CONFIG)\n","\n","generator.summary()\n","discriminator.summary()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"u4vxR-ZJXn0U","executionInfo":{"status":"ok","timestamp":1768882330041,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rajesh Chillapalli","userId":"18375985042517881039"}}},"outputs":[],"source":["# Combined Vanilla GAN model wrapper (for organization like vanilla_gan.py)\n","class VanillaGAN(tf.keras.Model):\n","    def __init__(self, generator, discriminator, config=CONFIG):\n","        super().__init__()\n","        self.generator = generator\n","        self.discriminator = discriminator\n","        self.latent_dim = config[\"latent_dim\"]\n","\n","        self.d_optimizer = optimizers.Adam(config[\"lr\"], beta_1=config[\"beta1\"])\n","        self.g_optimizer = optimizers.Adam(config[\"lr\"], beta_1=config[\"beta1\"])\n","        self.loss_fn = losses.BinaryCrossentropy(from_logits=False)\n","\n","        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n","        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n","\n","    def generate_noise(self, batch_size):\n","        return tf.random.normal(shape=(batch_size, self.latent_dim))\n","\n","    def train_step(self, real_images):\n","        batch_size = tf.shape(real_images)[0]\n","\n","        # -------------------\n","        # Train Discriminator\n","        # -------------------\n","        random_noise = self.generate_noise(batch_size)\n","\n","        with tf.GradientTape() as tape:\n","            fake_images = self.generator(random_noise, training=True)\n","\n","            # Labels: real=1, fake=0\n","            real_labels = tf.ones((batch_size, 1))\n","            fake_labels = tf.zeros((batch_size, 1))\n","\n","            real_logits = self.discriminator(real_images, training=True)\n","            fake_logits = self.discriminator(fake_images, training=True)\n","\n","            d_loss_real = self.loss_fn(real_labels, real_logits)\n","            d_loss_fake = self.loss_fn(fake_labels, fake_logits)\n","            d_loss = d_loss_real + d_loss_fake\n","\n","        grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n","        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_variables))\n","\n","        # ---------------\n","        # Train Generator\n","        # ---------------\n","        random_noise = self.generate_noise(batch_size)\n","        with tf.GradientTape() as tape:\n","            fake_images = self.generator(random_noise, training=True)\n","            # Generator wants discriminator to output 1 for fake images\n","            misleading_labels = tf.ones((batch_size, 1))\n","            fake_logits = self.discriminator(fake_images, training=True)\n","            g_loss = self.loss_fn(misleading_labels, fake_logits)\n","\n","        grads = tape.gradient(g_loss, self.generator.trainable_variables)\n","        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_variables))\n","\n","        self.d_loss_metric.update_state(d_loss)\n","        self.g_loss_metric.update_state(g_loss)\n","\n","        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}\n","\n","    @property\n","    def metrics(self):\n","        return [self.d_loss_metric, self.g_loss_metric]\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-eGNkdrUXrLQ","executionInfo":{"status":"ok","timestamp":1768882330043,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rajesh Chillapalli","userId":"18375985042517881039"}}},"outputs":[],"source":["# Fixed noise for monitoring progress\n","fixed_noise = tf.random.normal(shape=(16, CONFIG[\"latent_dim\"]))\n","\n","def save_sample_images(generator, epoch, samples_dir=CONFIG[\"samples_dir\"]):\n","    preds = generator(fixed_noise, training=False)\n","    imgs = (preds + 1.0) / 2.0  # back to [0,1]\n","\n","    fig, axes = plt.subplots(4, 4, figsize=(4, 4))\n","    idx = 0\n","    for i in range(4):\n","        for j in range(4):\n","            ax = axes[i, j]\n","            ax.imshow(imgs[idx, :, :, 0], cmap=\"gray\")\n","            ax.axis(\"off\")\n","            idx += 1\n","    plt.tight_layout()\n","    os.makedirs(samples_dir, exist_ok=True)\n","    out_path = os.path.join(samples_dir, f\"epoch_{epoch:03d}.png\")\n","    plt.savefig(out_path)\n","    plt.close(fig)\n","    print(f\"Saved samples to {out_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBhnqY56YAEh","outputId":"3a76c0a6-8b73-4e91-a9f9-c177577f606b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 0.9620 | G_loss: 1.1748\n","Saved samples to samples/epoch_001.png\n","\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.0541 | G_loss: 1.0804\n","\n","Epoch 3/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.1112 | G_loss: 1.0465\n","\n","Epoch 4/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.1580 | G_loss: 1.0140\n","\n","Epoch 5/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.1791 | G_loss: 0.9888\n","Saved samples to samples/epoch_005.png\n","\n","Epoch 6/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.1959 | G_loss: 0.9783\n","\n","Epoch 7/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.2080 | G_loss: 0.9737\n","\n","Epoch 8/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.2228 | G_loss: 0.9611\n","\n","Epoch 9/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.2236 | G_loss: 0.9513\n","\n","Epoch 10/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.2331 | G_loss: 0.9452\n","Saved samples to samples/epoch_010.png\n","Saved checkpoints at epoch 10\n","\n","Epoch 11/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.2354 | G_loss: 0.9349\n","\n","Epoch 12/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.2410 | G_loss: 0.9358\n","\n","Epoch 13/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.2524 | G_loss: 0.9247\n","\n","Epoch 14/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.2553 | G_loss: 0.9214\n","\n","Epoch 15/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.2573 | G_loss: 0.9111\n","Saved samples to samples/epoch_015.png\n","\n","Epoch 16/100\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["D_loss: 1.2611 | G_loss: 0.9067\n","\n","Epoch 17/100\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 388/1039 [00:08<00:14, 45.66it/s]"]}],"source":["# Training loop (manual, similar to train.py)\n","gan = VanillaGAN(generator, discriminator, CONFIG)\n","\n","@tf.function\n","def train_step(images):\n","    return gan.train_step(images)\n","\n","def train_gan(train_ds, epochs=CONFIG[\"epochs\"]):\n","    for epoch in range(1, epochs + 1):\n","        print(f\"\\nEpoch {epoch}/{epochs}\")\n","        gan.d_loss_metric.reset_state()\n","        gan.g_loss_metric.reset_state()\n","\n","        for batch in tqdm(train_ds, leave=False):\n","            train_step(batch)\n","\n","        d_loss = gan.d_loss_metric.result().numpy()\n","        g_loss = gan.g_loss_metric.result().numpy()\n","        print(f\"D_loss: {d_loss:.4f} | G_loss: {g_loss:.4f}\")\n","\n","        # Save samples periodically\n","        if epoch % 5 == 0 or epoch == 1:\n","            save_sample_images(gan.generator, epoch)\n","\n","        # Checkpoint (simple H5 save)\n","        if epoch % 10 == 0:\n","            g_path = os.path.join(CONFIG[\"checkpoints_dir\"], f\"G_epoch_{epoch:03d}.keras\")\n","            d_path = os.path.join(CONFIG[\"checkpoints_dir\"], f\"D_epoch_{epoch:03d}.keras\")\n","            gan.generator.save(g_path)\n","            gan.discriminator.save(d_path)\n","            print(f\"Saved checkpoints at epoch {epoch}\")\n","\n","train_gan(train_ds, epochs=CONFIG[\"epochs\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5Naef9eYCMW"},"outputs":[],"source":["g_final_path = os.path.join(CONFIG[\"checkpoints_dir\"], \"G_final.keras\")\n","d_final_path = os.path.join(CONFIG[\"checkpoints_dir\"], \"D_final.keras\")\n","gan.generator.save(g_final_path)\n","gan.discriminator.save(d_final_path)\n","print(\"Saved final models.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Hbzo182Ydxu"},"outputs":[],"source":["# Visualize a grid of generated images\n","def show_generated_grid(generator, n=25):\n","    noise = tf.random.normal((n, CONFIG[\"latent_dim\"]))\n","    preds = generator(noise, training=False)\n","    imgs = (preds + 1.0) / 2.0\n","\n","    side = int(np.sqrt(n))\n","    fig, axes = plt.subplots(side, side, figsize=(side, side))\n","    idx = 0\n","    for i in range(side):\n","        for j in range(side):\n","            ax = axes[i, j]\n","            ax.imshow(imgs[idx, :, :, 0], cmap=\"gray\")\n","            ax.axis(\"off\")\n","            idx += 1\n","    plt.tight_layout()\n","    plt.show()\n","\n","show_generated_grid(gan.generator, n=25)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6G4lX51rYg2C"},"outputs":[],"source":["# Simple diversity score: measure variance across generated images\n","def compute_diversity_score(generator, num_samples=1000):\n","    noise = tf.random.normal((num_samples, CONFIG[\"latent_dim\"]))\n","    preds = generator(noise, training=False).numpy()\n","    preds = (preds + 1.0) / 2.0\n","\n","    # Flatten images and compute variance across the dataset\n","    flat = preds.reshape(num_samples, -1)\n","    variance_per_pixel = flat.var(axis=0)\n","    diversity_score = variance_per_pixel.mean()\n","    return diversity_score\n","\n","diversity = compute_diversity_score(gan.generator, num_samples=512)\n","print(\"Diversity score (higher ~ more variation):\", diversity)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJ1q-AJPYjCo"},"outputs":[],"source":["# Train a simple classifier on real MNIST digits and compare confidence on real vs fake\n","def train_simple_classifier(train_ds, val_ds):\n","    model = models.Sequential([\n","        layers.Input(shape=(CONFIG[\"image_size\"], CONFIG[\"image_size\"], CONFIG[\"channels\"])),\n","        layers.Conv2D(32, 3, activation=\"relu\"),\n","        layers.MaxPooling2D(),\n","        layers.Conv2D(64, 3, activation=\"relu\"),\n","        layers.MaxPooling2D(),\n","        layers.Flatten(),\n","        layers.Dense(64, activation=\"relu\"),\n","        layers.Dense(10, activation=\"softmax\")\n","    ])\n","    model.compile(optimizer=\"adam\",\n","                  loss=\"sparse_categorical_crossentropy\",\n","                  metrics=[\"accuracy\"])\n","\n","    # Reload MNIST with labels (for simplicity)\n","    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","    x = np.concatenate([x_train, x_test], axis=0).astype(\"float32\")\n","    y = np.concatenate([y_train, y_test], axis=0)\n","    x = np.expand_dims(x, -1)\n","    x = (x / 127.5) - 1.0\n","\n","    model.fit(x, y, batch_size=128, epochs=3, validation_split=0.1, verbose=2)\n","    return model\n","\n","classifier = train_simple_classifier(train_ds, val_ds)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ElkBTmcaYl38"},"outputs":[],"source":["# Realism score: classifier confidence on generated images\n","def classifier_realism_score(generator, classifier, num_samples=1000):\n","    noise = tf.random.normal((num_samples, CONFIG[\"latent_dim\"]))\n","    fake_imgs = generator(noise, training=False)\n","    # Rescale to [-1,1] already; classifier expects same normalization\n","    preds = classifier.predict(fake_imgs, verbose=0)\n","    confidences = preds.max(axis=1)\n","    return confidences.mean()\n","\n","realism = classifier_realism_score(gan.generator, classifier, num_samples=512)\n","print(\"Classifier-based realism score:\", realism)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UNbe2KWYpXe"},"outputs":[],"source":["# Inference utilities: generate N images and display/save\n","def generate_and_save(generator, n_images=16, out_dir=\"generated_batch\"):\n","    os.makedirs(out_dir, exist_ok=True)\n","    noise = tf.random.normal((n_images, CONFIG[\"latent_dim\"]))\n","    preds = generator(noise, training=False)\n","    imgs = (preds + 1.0) / 2.0\n","\n","    for i in range(n_images):\n","        img = imgs[i, :, :, 0]\n","        plt.imsave(os.path.join(out_dir, f\"img_{i:04d}.png\"), img, cmap=\"gray\")\n","    print(f\"Saved {n_images} images to {out_dir}\")\n","\n","generate_and_save(gan.generator, n_images=32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5KzVCZjYr3q"},"outputs":[],"source":["# Install Streamlit and ngrok for public URL\n","!pip install -q streamlit pyngrok\n","\n","# Download ngrok (one-time setup)\n","!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n","!tar xvzf ngrok-v3-stable-linux-amd64.tgz\n","!./ngrok authtoken YOUR_NGROK_TOKEN  # Get free token from ngrok.com\n"]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from PIL import Image\n","import zipfile\n","from datetime import datetime\n","import io\n","\n","# Load your trained Generator (from checkpoints)\n","@st.cache_resource\n","def load_generator():\n","    generator = tf.keras.models.load_model(\"checkpoints/G_final.keras\")\n","    return generator\n","\n","# Generate images\n","def generate_images(generator, n_images, latent_dim=100, img_size=64, channels=1):\n","    noise = tf.random.normal([n_images, latent_dim])\n","    predictions = generator(noise, training=False)\n","\n","    # Denormalize from [-1,1] to [0,1]\n","    predictions = (predictions + 1) / 2\n","    return predictions.numpy()\n","\n","# Main app\n","st.set_page_config(page_title=\"Synthetic Image Generator\", layout=\"wide\")\n","st.title(\"🔬 Privacy-Preserving Synthetic Image Generator\")\n","st.markdown(\"**Vanilla GAN Deployment** | Generate synthetic images for data augmentation\")\n","\n","# Sidebar controls\n","st.sidebar.header(\"Generation Controls\")\n","n_images = st.sidebar.slider(\"Number of images\", 1, 100, 16)\n","seed = st.sidebar.slider(\"Random seed\", 0, 10000, 42)\n","img_size = st.sidebar.selectbox(\"Image size\", [28, 64, 128])\n","batch_size = st.sidebar.slider(\"Batch size\", 8, 64, 16)\n","\n","# Load model\n","if 'generator' not in st.session_state:\n","    with st.spinner(\"Loading trained Generator...\"):\n","        st.session_state.generator = load_generator()\n","st.success(\"✅ Generator loaded successfully!\")\n","\n","# Generate button\n","if st.button(\"🚀 Generate Synthetic Images\", type=\"primary\"):\n","    with st.spinner(\"Generating images...\"):\n","        np.random.seed(seed)\n","        images = generate_images(\n","            st.session_state.generator,\n","            n_images,\n","            latent_dim=100,\n","            img_size=img_size,\n","            channels=1\n","        )\n","\n","        # Display grid\n","        cols = st.columns(4)\n","        for i, img in enumerate(images):\n","            col_idx = i % 4\n","            with cols[col_idx]:\n","                st.image(img.squeeze(), caption=f\"Synthetic #{i+1}\", use_column_width=True)\n","\n","        # Metrics\n","        diversity = np.var(images.reshape(n_images, -1), axis=0).mean()\n","        st.metric(\"Diversity Score\", f\"{diversity:.4f}\")\n","\n","        # Download options\n","        st.download_button(\n","            label=\"💾 Download ZIP\",\n","            data=zip_images(images),\n","            file_name=f\"synthetic_images_{datetime.now().strftime('%Y%m%d_%H%M')}.zip\",\n","            mime=\"application/zip\"\n","        )\n","\n","def zip_images(images):\n","    \"\"\"Convert images to ZIP bytes\"\"\"\n","    zip_buffer = io.BytesIO()\n","    with zipfile.ZipFile(zip_buffer, 'w') as zf:\n","        for i, img in enumerate(images):\n","            img_pil = Image.fromarray((img.squeeze() * 255).astype(np.uint8))\n","            img_buffer = io.BytesIO()\n","            img_pil.save(img_buffer, format='PNG')\n","            zf.writestr(f\"synthetic_{i+1:03d}.png\", img_buffer.getvalue())\n","    zip_buffer.seek(0)\n","    return zip_buffer.getvalue()\n","\n","# Demo section\n","st.markdown(\"---\")\n","st.header(\"📊 Demo: Latent Space Interpolation\")\n","if st.button(\"Show Interpolation\"):\n","    interp_images = interpolate_demo(st.session_state.generator)\n","    st.image(interp_images, caption=\"Latent space morphing\", use_column_width=True)\n","\n","def interpolate_demo(generator, steps=10):\n","    \"\"\"Create smooth interpolation between two latent vectors\"\"\"\n","    z1 = tf.random.normal([1, 100])\n","    z2 = tf.random.normal([1, 100])\n","    images = []\n","    for alpha in np.linspace(0, 1, steps):\n","        z_interp = (1-alpha) * z1 + alpha * z2\n","        img = generator(z_interp, training=False)\n","        img = (img + 1) / 2\n","        images.append(img[0].numpy())\n","    return np.hstack(images)\n","\n","# Footer\n","st.markdown(\"---\")\n","st.markdown(\"\"\"\n","*Built with Vanilla GAN for privacy-preserving data augmentation*\n","**Compliant with GDPR, HIPAA, DPDP Act** | No real data memorized\n","\"\"\")\n"],"metadata":{"id":"lKwIFAklAg9M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start Streamlit in background + ngrok tunnel\n","import subprocess\n","import threading\n","import time\n","import os\n","\n","# Terminal 1: Start Streamlit\n","def run_streamlit():\n","    os.system(\"streamlit run app.py --server.port 8501 --server.address 0.0.0.0 &\")\n","\n","# Terminal 2: ngrok tunnel\n","def start_ngrok():\n","    time.sleep(5)  # Wait for Streamlit\n","    os.system(\"./ngrok http 8501\")\n","\n","# Run both\n","threading.Thread(target=run_streamlit).start()\n","threading.Thread(target=start_ngrok).start()\n","\n","print(\"🚀 Streamlit app starting... Check the ngrok URL below in 10-20 seconds:\")\n","print(\"Public URL will appear automatically\")\n"],"metadata":{"id":"eN5BtD_pAyVO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    # Save final models - CRITICAL for deployment\n","g_final_path = os.path.join(CONFIG[\"checkpoints_dir\"], \"G_final.keras\")\n","d_final_path = os.path.join(CONFIG[\"checkpoints_dir\"], \"D_final.keras\")\n","gan.generator.save(g_final_path)\n","gan.discriminator.save(d_final_path)\n","print(\"✅ Saved final models: G_final.keras, D_final.keras\")\n","print(\"Files in checkpoints:\", os.listdir(\"checkpoints\"))\n"],"metadata":{"id":"eMUFJ0nnA4f4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_generated_grid(generator, n=16):\n","    noise = tf.random.normal((n, CONFIG[\"latent_dim\"]))\n","    preds = generator(noise, training=False)\n","    imgs = (preds + 1.0) / 2.0\n","    side = int(np.sqrt(n))\n","\n","    fig, axes = plt.subplots(side, side, figsize=(8, 8))\n","    idx = 0\n","    for i in range(side):\n","        for j in range(side):\n","            ax = axes[i, j] if side > 1 else axes[j]\n","            img = imgs[idx]\n","            ax.imshow(img.numpy().squeeze(), cmap=\"gray\")\n","            ax.axis(\"off\")\n","            idx += 1\n","    plt.tight_layout()\n","    plt.show()\n","\n","show_generated_grid(gan.generator, n=16)\n","print(\"✅ Visual evaluation complete\")"],"metadata":{"id":"OY1-vYoxLW8n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install ngrok for public URL\n","!pip install -q pyngrok\n","!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz -O ngrok.tgz\n","!tar xvzf ngrok.tgz\n"],"metadata":{"id":"sYz-BoukLaLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./ngrok config add-authtoken 37WrtcnwEjuVhG10CNAzfMajLAl_9Xa6wKDE7kt9tUZ8C3fY\n"],"metadata":{"id":"er_U90mFLlvP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml"],"metadata":{"id":"-PsJWCYCNT1R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile app_fixed.py\n","import streamlit as st\n","import tensorflow as tf\n","import numpy as np\n","from PIL import Image\n","import io\n","import zipfile\n","from datetime import datetime\n","import os\n","\n","st.set_page_config(layout=\"wide\")\n","st.title(\"🔬 Synthetic Image Generator\")\n","st.markdown(\"**Vanilla GAN - Privacy-Preserving Data Augmentation**\")\n","\n","# File check\n","st.sidebar.markdown(\"**Files in checkpoints/**\")\n","st.sidebar.write(os.listdir(\"checkpoints\"))\n","\n","if not os.path.exists(\"checkpoints/G_final.keras\"):\n","    st.error(\"❌ Run Cell 2 first to save G_final.keras\")\n","    st.stop()\n","\n","@st.cache_resource\n","def load_generator():\n","    return tf.keras.models.load_model(\"checkpoints/G_final.keras\", safe_mode=False)\n","\n","generator = load_generator()\n","st.success(\"✅ Generator loaded successfully!\")\n","\n","# Controls\n","col1, col2 = st.columns([1,1])\n","with col1:\n","    n_images = st.slider(\"Number of images\", 1, 64, 16)\n","with col2:\n","    seed = st.slider(\"Random seed\", 0, 9999, 42)\n","\n","if st.button(\"🚀 GENERATE SYNTHETIC IMAGES\", type=\"primary\"):\n","    np.random.seed(seed)\n","    noise = tf.random.normal([n_images, 100])\n","    images = generator(noise, training=False)\n","    images = (images + 1) / 2.0\n","\n","    # Show grid\n","    cols = st.columns(4)\n","    for i, img in enumerate(images):\n","        with cols[i % 4]:\n","            st.image(img.squeeze(), caption=f\"Synthetic #{i+1}\", use_column_width=True)\n","\n","    # ZIP download\n","    buf = io.BytesIO()\n","    with zipfile.ZipFile(buf, 'w') as zf:\n","        for i, img in enumerate(images):\n","            pil_img = Image.fromarray((img.squeeze()*255).astype(np.uint8))\n","            pil_img.save(zf, format='PNG')\n","    buf.seek(0)\n","    st.download_button(\"💾 Download ZIP Dataset\", buf.getvalue(),\n","                      f\"synthetic_dataset_{datetime.now().strftime('%Y%m%d_%H%M')}.zip\")\n"],"metadata":{"id":"hQQMKkOJQax2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pkill -f streamlit\n","from pyngrok import ngrok\n","ngrok.kill()\n"],"metadata":{"id":"dminyslpQgAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile app_working.py\n","import streamlit as st\n","import tensorflow as tf\n","import numpy as np\n","from PIL import Image\n","import io\n","import zipfile\n","from datetime import datetime\n","import os\n","\n","# Page config\n","st.set_page_config(layout=\"wide\", page_title=\"GAN Generator\")\n","\n","st.markdown(\"\"\"\n","# 🔬 **Synthetic Image Generator**\n","*Vanilla GAN - Privacy-Preserving Data Augmentation*\n","\"\"\")\n","\n","# Load generator with error handling\n","@st.cache_resource\n","def load_model():\n","    model_path = \"checkpoints/G_final.keras\"\n","    if not os.path.exists(model_path):\n","        st.error(f\"❌ {model_path} not found\")\n","        st.stop()\n","    return tf.keras.models.load_model(model_path)\n","\n","generator = load_model()\n","st.success(\"✅ Generator loaded!\")\n","\n","# Controls\n","col1, col2 = st.columns(2)\n","n_images = col1.slider(\"Images\", 1, 64, 16)\n","seed = col2.slider(\"Seed\", 0, 9999, 42)\n","\n","# Generate button\n","if st.button(\"🚀 GENERATE SYNTHETIC IMAGES\", type=\"primary\"):\n","    with st.spinner(\"Generating...\"):\n","        np.random.seed(seed)\n","        noise = tf.random.normal([n_images, 100])\n","        images = generator(noise, training=False)\n","        images = (images + 1) / 2.0  # Denormalize [-1,1] -> [0,1]\n","\n","        # Display images\n","        cols = st.columns(4)\n","        for i, img in enumerate(images):\n","            with cols[i % 4]:\n","                st.image(img.squeeze(), caption=f\"Synth #{i+1}\", use_column_width=True)\n","\n","        # Download ZIP\n","        buf = io.BytesIO()\n","        with zipfile.ZipFile(buf, \"w\") as zf:\n","            for i, img in enumerate(images):\n","                pil_img = Image.fromarray((img.squeeze() * 255).astype(np.uint8))\n","                pil_img.save(zf, \"PNG\")\n","        buf.seek(0)\n","        st.download_button(\"💾 Download ZIP\", buf, f\"gan_synthetic_{datetime.now().strftime('%Y%m%d_%H%M')}.zip\")\n","\n","st.markdown(\"---\")\n","st.markdown(\"*Compliant with GDPR, HIPAA, DPDP Act*\")\n"],"metadata":{"id":"CXfK5NYnRK8g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# QUICK TEST - Run this to verify generator works\n","generator = tf.keras.models.load_model(\"checkpoints/G_final.keras\")\n","noise = tf.random.normal([4, 100])\n","test_images = generator(noise, training=False)\n","test_images = (test_images + 1) / 2.0\n","\n","import matplotlib.pyplot as plt\n","fig, axes = plt.subplots(2, 2, figsize=(6,6))\n","for i, ax in enumerate(axes.flat):\n","    ax.imshow(test_images[i].numpy().squeeze(), cmap='gray') # Added .numpy() here\n","    ax.axis('off')\n","plt.tight_layout()\n","plt.show()\n","print(\"✅ GENERATOR WORKS!\")"],"metadata":{"id":"e_OfhhelRQKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pkill -f streamlit\n","!pip install -q gradio\n","from pyngrok import ngrok\n","ngrok.kill()\n"],"metadata":{"id":"qKAQM1k4RS8u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gradio as gr\n","import tensorflow as tf\n","import numpy as np\n","from PIL import Image\n","import zipfile\n","import io\n","from datetime import datetime\n","import os\n","\n","# Load generator globally (outside Gradio)\n","print(\"Loading generator...\")\n","generator = tf.keras.models.load_model(\"checkpoints/G_final.keras\")\n","print(\"✅ Generator loaded!\")\n","\n","def generate_images(n_images, seed):\n","    np.random.seed(seed)\n","    noise = tf.random.normal([n_images, 100])\n","    images = generator(noise, training=False)\n","    images = (images + 1) / 2.0\n","\n","    # Convert to PIL for Gradio\n","    pil_images = []\n","    for img in images:\n","        pil_img = Image.fromarray((img.squeeze() * 255).astype(np.uint8))\n","        pil_images.append(pil_img)\n","\n","    return pil_images\n","\n","def create_zip(n_images, seed):\n","    np.random.seed(seed)\n","    noise = tf.random.normal([n_images, 100])\n","    images = generator(noise, training=False)\n","    images = (images + 1) / 2.0\n","\n","    buf = io.BytesIO()\n","    with zipfile.ZipFile(buf, \"w\") as zf:\n","        for i, img in enumerate(images):\n","            pil_img = Image.fromarray((img.squeeze() * 255).astype(np.uint8))\n","            pil_img.save(zf, \"PNG\")\n","    buf.seek(0)\n","    return buf.getvalue()\n","\n","# Gradio interface\n","with gr.Blocks(title=\"GAN Generator\") as demo:\n","    gr.Markdown(\"# 🔬 Synthetic Image Generator\")\n","    gr.Markdown(\"*Vanilla GAN - Privacy-Preserving Data Augmentation*\")\n","\n","    with gr.Row():\n","        n_slider = gr.Slider(1, 64, value=16, label=\"Number of images\")\n","        seed_slider = gr.Slider(0, 9999, value=42, label=\"Random seed\")\n","\n","    generate_btn = gr.Button(\"🚀 Generate Images\", variant=\"primary\", size=\"lg\")\n","\n","    gallery = gr.Gallery(label=\"Synthetic Images\")\n","\n","    # Create a button to trigger the zip creation and a File component to receive the output\n","    download_zip_button = gr.Button(\"💾 Create and Download ZIP\", variant=\"secondary\")\n","    zip_download_output = gr.File(label=\"Download ZIP Dataset\", file_count=\"single\", interactive=False)\n","\n","    generate_btn.click(\n","        generate_images,\n","        inputs=[n_slider, seed_slider],\n","        outputs=gallery\n","    )\n","\n","    download_zip_button.click(\n","        create_zip,\n","        inputs=[n_slider, seed_slider],\n","        outputs=zip_download_output\n","    )\n","\n","demo.launch(share=True)"],"metadata":{"id":"TZA1xEl5R0un"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import os\n","print(\"📁 PROJECT FILES:\")\n","print(\"- Samples:\", len(os.listdir(\"samples\")), \"images ✓\")\n","print(\"- G_final.keras:\", os.path.exists(\"checkpoints/G_final.keras\"), \"✓\")\n","\n","# Show latest training sample\n","files = sorted(os.listdir(\"samples\"))\n","img = plt.imread(f\"samples/{files[-1]}\")\n","plt.figure(figsize=(10,8))\n","plt.imshow(img)\n","plt.title(\"✅ Training Complete - Latest Samples\", fontsize=16, pad=20)\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"hDDuAMhfT87A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ipywidgets as widgets\n","from IPython.display import display\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","generator = tf.keras.models.load_model(\"checkpoints/G_final.keras\")\n","\n","@widgets.interact(n=(1,36,1), seed=(0,999,1))\n","def demo(n=16, seed=42):\n","    np.random.seed(seed)\n","    noise = tf.random.normal([n, 100])\n","    images = generator(noise, training=False)\n","    images = (images + 1) / 2\n","\n","    rows = (n+3)//4\n","    fig, axes = plt.subplots(rows, 4, figsize=(12,3*rows))\n","    axes = axes.flat if rows > 1 else [axes]\n","\n","    for i in range(n):\n","        ax = axes[i]\n","        ax.imshow(images[i].numpy().squeeze(), cmap='gray')\n","        ax.set_title(f\"Synth #{i+1}\", fontsize=10)\n","        ax.axis('off')\n","    plt.suptitle(f\"🚀 LIVE GENERATION (n={n}, seed={seed})\", fontsize=16)\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"_G14P09_U8RM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"n6L5oWKdU-ih"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}